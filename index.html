<!DOCTYPE HTML>
<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?031f1c7d5b09cd718f3482df88fc8aa4";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Xu Luo</title>
  
  <meta name="author" content="Xu Luo">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/seal_icon.png">
  <style>
		ul{
			list-style-type: disc;
		}
	</style>
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Xu Luo</name>
              </p>
              <p>I am currently a Ph.D student at University of Electronic Science and Technology of China (UESTC). 
		</p>
		    <p>  
		 I am interested in understanding how visual representations behave in face of out-of-distribution tasks with limited labeled data, and in developing new algorithms that enable rapid model adaptation. This interesting direction connects several fields including visual representation learning, few-shot learning, meta-learning, model robustness and transfer learning.  
		    </p>  
		      
		      
              
              <p style="text-align:center">
                <a href="mailto:Frank.Luox@outlook.com">Email</a> &nbsp/&nbsp
		<a href="./CV.pdf">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.com.hk/citations?view_op=list_works&hl=zh-CN&hl=zh-CN&user=HXCdZMEAAAAJ">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/Frankluox">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/XuLuo-2.JPG"><img style="width:80%;max-width:80%" alt="profile photo" src="images/XuLuo-2.JPG" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>News</heading>
              <p>
		<li>[2022/09] One paper was accepted to NeurIPS‘22.</li>
		<li>[2022/05] One paper was accepted to ICML‘22.</li>
                <li>[2021/09] One paper was accepted to NeurIPS‘21.</li>
                <li>[2021/03] One paper was accepted to ICME‘21.</li>
              </p>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Publications</heading>
            </td>
          </tr>
        </tbody></table>
	      
	      
	<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='images/train_test_disentangle.jpg' width="180">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>A Closer Look at Few-shot Classification Again</papertitle>
              <br>
		    <strong>Xu Luo*</strong>,
		    <a href="https://openreview.net/profile?id=~Hao_Wu37">Hao Wu*</a>,
		    <a href="https://openreview.net/profile?id=~Ji_Zhang4">Ji Zhang</a>,
		    <a href="https://lianligao.github.io/">Lianli Gao</a>,
		    <a href="https://scholar.google.com/citations?user=_UtHiH4AAAAJ&hl=zh-CN&oi=sra">Jing Xu</a>,
		    <a href="https://cfm.uestc.edu.cn/~songjingkuan/">Jingkuan Song</a>,
              <br>
              <em>Arxiv</em>, 2023
              <br>
	      <a href="https://arxiv.org/abs/2301.12246">[PDF]</a> 
              [Code]
              <p></p>
              <p>Empirically proving the disentanglement of training and adaptation algorithms in few-shot calssification, and performing interesting analysis of each phase that leads to the discovery of several impotant observations.</p>
            </td>
          </tr> 
	      
	<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='images/showing_img_nips2022.png' width="180">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Alleviating the Sample Selection Bias in Few-shot Learning by Removing Projection to the Centroid</papertitle>
              <br>
              <a href="https://scholar.google.com/citations?user=_UtHiH4AAAAJ&hl=zh-CN&oi=sra">Jing Xu</a>,
		    <strong>Xu Luo</strong>,
		    <a href="https://openreview.net/profile?id=~Xinglin_Pan1">Xinglin Pan</a>,
		    <a href="https://yananlix1.github.io/">Yanan Li</a>,
		    <a href="https://wenjiepei.github.io/">Wenjie Pei</a>,
							<a href="http://faculty.hitsz.edu.cn/xuzenglin">Zenglin Xu</a>
              <br>
              <em>NeurIPS</em>, 2022 &nbsp <font color=#FF8080><strong>(Spotlight)</strong></font>
              <br>
	      <a href="https://arxiv.org/abs/2210.16834">[PDF]</a> 
              <a href="https://github.com/KikimorMay/FSL-TCBR">[Code]</a>
              <p></p>
              <p>Revealing a strong bias caused by the centroid of features in each few-shot learning task. A simple method is designed to rectify this bias by removing the dimension along the direction of task centroid from the feature space.</p>
            </td>
          </tr> 
        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='images/showing_img5.png' width="180">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Channel Importance Matters in Few-Shot Image Classification</papertitle>
              <br>
              <strong>Xu Luo</strong>,
							<a href="https://scholar.google.com/citations?user=_UtHiH4AAAAJ&hl=zh-CN&oi=sra">Jing Xu</a>, 
							<a href="http://faculty.hitsz.edu.cn/xuzenglin">Zenglin Xu</a>
              <br>
              <em>ICML</em>, 2022
              <br>
              <a href="https://arxiv.org/abs/2206.08126">[PDF]</a>	
              <a href="https://github.com/Frankluox/Channel_Importance_FSL">[Code]</a>
              <p></p>
              <p>Revealing and analyzing the channel bias problem that we found critical in few-shot learning, through a simple channel-wise feature transformation applied only at test time.</p>
            </td>
          </tr> 
		
          <tr onmouseout="npil_stop()" onmouseover="npil_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='npil_image'>
                  <img src='images/showing_img3.png' width="180"></div>
                <img src='images/showing_img3.png' width="180">
              </div>
              <script type="text/javascript">
                function npil_start() {
                  document.getElementById('npil_image').style.opacity = "1";
                }

                function npil_stop() {
                  document.getElementById('npil_image').style.opacity = "0";
                }
                npil_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Rectifying the Shortcut Learning of Background for Few-Shot Learning</papertitle>
              <br>

              <strong>Xu Luo</strong>,
              <a href="https://joinwei-pku.github.io/longhuiwei.github.io/">Longhui Wei</a>, 
              <a href="https://openreview.net/profile?id=~Liangjian_Wen1">Liangjian Wen</a>,
              <a href="https://scholar.google.com/citations?user=8Of_NYQAAAAJ&hl=zh-CN">Jinrong Yang</a>,
              <a href="http://lingxixie.com/Home.html">Lingxi xie</a>,
              <a href="http://faculty.hitsz.edu.cn/xuzenglin">Zenglin Xu</a>,
              <a href="https://faculty.xidian.edu.cn/TQ1/zh_CN/index.htm">Qi Tian</a>
              <br>
							<em>NeurIPS</em>, 2021
              <br>
              <a href="https://arxiv.org/pdf/2107.07746.pdf">[PDF]</a> 
              <a href="https://github.com/Frankluox/FewShotCodeBase">[Code]</a>
              <p></p>
              <p>
              Identifying image background
              as a shortcut knowledge ungeneralizable
              beyond training categories in Few-Shot Learning. A novel framework, COSOC, is designed to
              tackle this problem.
              </p>
            </td>
          </tr>
					
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='images/showing_img4.png' width="180">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Boosting Few-Shot Classification with View-Learnable Contrastive Learning</papertitle>
              <br>
              <strong>Xu Luo</strong>,
							<a href="https://openreview.net/profile?id=~Yuxuan_Chen2">Yuxuan Chen</a>,
							<a href="https://openreview.net/profile?id=~Liangjian_Wen1">Liangjian Wen</a>, 
							<a href="https://scholar.google.com/citations?user=gXpdHzMAAAAJ&hl=en">Lili Pan</a>,
							<a href="http://faculty.hitsz.edu.cn/xuzenglin">Zenglin Xu</a>
              <br>
              <em>ICME</em>, 2021 
              <br>
              <a href="https://arxiv.org/pdf/2107.09242">[PDF]</a>
              <a href="https://github.com/Frankluox/FewShotCodeBase">[Code]</a>
              <p></p>
              <p>Applying contrastive learning to Few-Shot Learning, with views generated in a learning-to-learn fashion.</p>
            </td>
          </tr> 
	</tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Reviewing</heading>
              <p>
                <li>ICML: 2022</li>
		<li>CVPR: 2023</li>   
		<li>ECCV: 2022</li>
		<li>AAAI: 2023</li>
		<li>Workshops: L3D-IVU at CVPR 2022, 2023</li>
              </p>
            </td>
          </tr>
        </tbody></table>
          

          

        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;vertical-align:middle;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="vertical-align:middle;font-size:small;">
                This well-designed template is borrowed from this <a href="https://jonbarron.info/">guy</a>
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
