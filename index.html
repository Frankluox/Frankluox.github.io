<!DOCTYPE HTML>
<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?031f1c7d5b09cd718f3482df88fc8aa4";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Xu Luo</title>
  
  <meta name="author" content="Xu Luo">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/seal_icon.png">
  <style>
		ul{
			list-style-type: disc;
		}
	</style>
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Xu Luo</name>
              </p>
              <p>I am currently pursuing a Ph.D. at UESTC, with a research internship at the Shanghai AI Lab. My primary research interest lies in advancing the state-of-the-art for generative AI models, including diffusion models and (multimodal) large language models (LLMs). Beyond these, I am fervently committed to actualizing the potential of these models, shaping them into autonomous agents capable of performing intricate tasks in real-world scenarios.
		</p>
		      
		      
              
              <p style="text-align:center">
                <a href="mailto:Frank.Luox@outlook.com">Email</a> &nbsp/&nbsp
		<a href="./CV.pdf">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?hl=en&user=HXCdZMEAAAAJ">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/Frankluox">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/XuLuo-2.JPG"><img style="width:80%;max-width:80%" alt="profile photo" src="images/XuLuo-2.JPG" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>News</heading>
              <p>
		<br>
		<strong>[2023/10]</strong> Regret to say that FSL is no longer a valuable research topic. My research focus has shifted from Few-Shot Learning (FSL) to the burgeoning field of generative AI. I am currently an intern at Shanghai AI Lab, working under the guidance of <a href="https://gaopengpjlab.github.io/">Peng Gao</a>.
		<br>
		<strong>[2023/04]</strong> Our systematic study on few-shot learning has been accepted at ICML'23! This project demanded a significant investment of time and revealed numerous unexpected findings. Check it out now!
		<br>
		<strong>[2022/05]</strong> Our paper, which uncovers fundamental problems inherent in few-shot learning, was accepted at ICML 2022.
		<br>
                <strong>[2021/09]</strong> My first top conference paper at NeurIPS 2021! The paper is not that good, but a good experience(:
              </p>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Publications</heading>
            </td>
          </tr>
        </tbody></table>

	<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='images/lessismore.png' width="180">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Less is More: On the Feature Redundancy of Pretrained Models When Transferring to Few-shot Tasks</papertitle>
              <br>
		    <strong>Xu Luo</strong>,
		    <a href="https://difanzou.github.io/">Difan Zou</a>,
		    <a href="https://lianligao.github.io/">Lianli Gao</a>,
		    <a href="http://faculty.hitsz.edu.cn/xuzenglin">Zenglin Xu</a>,
		    <a href="https://cfm.uestc.edu.cn/~songjingkuan/">Jingkuan Song</a>
              <br>
              <em>arXiv</em>, 2023
              <br>
	      <a href="https://arxiv.org/abs/2310.03843">[PDF]</a> 
              <p></p>
              <p>Uncovering and analyzing extreme feature redundancy phenomenon of pretrained vision models when transferring to few-shot tasks.</p>
            </td>
          </tr>

	<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='images/DETA.png' width="180">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>DETA: Denoised Task Adaptation for Few-shot Learning</papertitle>
              <br>
		    <a href="https://openreview.net/profile?id=~Ji_Zhang4">Ji Zhang</a>,
		    <a href="https://lianligao.github.io/">Lianli Gao</a>,
		    <strong>Xu Luo</strong>,
		    <a href="https://cfm.uestc.edu.cn/~shenht/">Hengtao Shen</a>,
		    <a href="https://cfm.uestc.edu.cn/~songjingkuan/">Jingkuan Song</a>
              <br>
              <em>ICCV</em>, 2023
              <br>
	      <a href="https://arxiv.org/abs/2303.06315">[PDF]</a> 
              <a href="https://github.com/nobody-1617/DETA">[Code]</a>
              <p></p>
              <p>Proposing DETA--a framework that solves potential data/label noise in downstream few-shot transfer tasks.</p>
            </td>
          </tr>
	      
	      
	<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='images/ICML_2023.jpeg' width="180">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>A Closer Look at Few-shot Classification Again</papertitle>
              <br>
		    <strong>Xu Luo*</strong>,
		    <a href="https://openreview.net/profile?id=~Hao_Wu37">Hao Wu*</a>,
		    <a href="https://openreview.net/profile?id=~Ji_Zhang4">Ji Zhang</a>,
		    <a href="https://lianligao.github.io/">Lianli Gao</a>,
		    <a href="https://scholar.google.com/citations?user=_UtHiH4AAAAJ&hl=zh-CN&oi=sra">Jing Xu</a>,
		    <a href="https://cfm.uestc.edu.cn/~songjingkuan/">Jingkuan Song</a>
              <br>
              <em>ICML</em>, 2023
              <br>
	      <a href="https://arxiv.org/abs/2301.12246">[PDF]</a> 
              <a href="https://github.com/Frankluox/CloserLookAgainFewShot">[Code]</a>
              <p></p>
              <p>Empirically proving the disentanglement of training and adaptation algorithms in few-shot classification, and performing interesting analysis of each phase that leads to the discovery of several important observations.</p>
            </td>
          </tr> 
	      
	<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='images/showing_img_nips2022.png' width="180">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Alleviating the Sample Selection Bias in Few-shot Learning by Removing Projection to the Centroid</papertitle>
              <br>
              <a href="https://scholar.google.com/citations?user=_UtHiH4AAAAJ&hl=zh-CN&oi=sra">Jing Xu</a>,
		    <strong>Xu Luo</strong>,
		    <a href="https://openreview.net/profile?id=~Xinglin_Pan1">Xinglin Pan</a>,
		    <a href="https://yananlix1.github.io/">Yanan Li</a>,
		    <a href="https://wenjiepei.github.io/">Wenjie Pei</a>,
							<a href="http://faculty.hitsz.edu.cn/xuzenglin">Zenglin Xu</a>
              <br>
              <em>NeurIPS</em>, 2022 &nbsp <font color=#FF8080><strong>(Spotlight)</strong></font>
              <br>
	      <a href="https://arxiv.org/abs/2210.16834">[PDF]</a> 
              <a href="https://github.com/KikimorMay/FSL-TCBR">[Code]</a>
              <p></p>
              <p>Revealing a strong bias caused by the centroid of features in each few-shot learning task. A simple method is designed to rectify this bias by removing the dimension along the direction of task centroid from the feature space.</p>
            </td>
          </tr> 
        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='images/showing_img5.png' width="180">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Channel Importance Matters in Few-Shot Image Classification</papertitle>
              <br>
              <strong>Xu Luo</strong>,
							<a href="https://scholar.google.com/citations?user=_UtHiH4AAAAJ&hl=zh-CN&oi=sra">Jing Xu</a>, 
							<a href="http://faculty.hitsz.edu.cn/xuzenglin">Zenglin Xu</a>
              <br>
              <em>ICML</em>, 2022
              <br>
              <a href="https://arxiv.org/abs/2206.08126">[PDF]</a>	
              <a href="https://github.com/Frankluox/Channel_Importance_FSL">[Code]</a>
              <p></p>
              <p>Revealing and analyzing the channel bias problem that we found critical in few-shot learning, through a simple channel-wise feature transformation applied only at test time.</p>
            </td>
          </tr> 
		
          <tr onmouseout="npil_stop()" onmouseover="npil_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='npil_image'>
                  <img src='images/showing_img3.png' width="180"></div>
                <img src='images/showing_img3.png' width="180">
              </div>
              <script type="text/javascript">
                function npil_start() {
                  document.getElementById('npil_image').style.opacity = "1";
                }

                function npil_stop() {
                  document.getElementById('npil_image').style.opacity = "0";
                }
                npil_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Rectifying the Shortcut Learning of Background for Few-Shot Learning</papertitle>
              <br>

              <strong>Xu Luo</strong>,
              <a href="https://joinwei-pku.github.io/longhuiwei.github.io/">Longhui Wei</a>, 
              <a href="https://openreview.net/profile?id=~Liangjian_Wen1">Liangjian Wen</a>,
              <a href="https://scholar.google.com/citations?user=8Of_NYQAAAAJ&hl=zh-CN">Jinrong Yang</a>,
              <a href="http://lingxixie.com/Home.html">Lingxi xie</a>,
              <a href="http://faculty.hitsz.edu.cn/xuzenglin">Zenglin Xu</a>,
              <a href="https://faculty.xidian.edu.cn/TQ1/zh_CN/index.htm">Qi Tian</a>
              <br>
							<em>NeurIPS</em>, 2021
              <br>
              <a href="https://arxiv.org/pdf/2107.07746.pdf">[PDF]</a> 
              <a href="https://github.com/Frankluox/FewShotCodeBase">[Code]</a>
              <p></p>
              <p>
              Identifying image background
              as a shortcut knowledge ungeneralizable
              beyond training categories in Few-Shot Learning. A novel framework, COSOC, is designed to
              tackle this problem.
              </p>
            </td>
          </tr>
					
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='images/showing_img4.png' width="180">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Boosting Few-Shot Classification with View-Learnable Contrastive Learning</papertitle>
              <br>
              <strong>Xu Luo</strong>,
							<a href="https://openreview.net/profile?id=~Yuxuan_Chen2">Yuxuan Chen</a>,
							<a href="https://openreview.net/profile?id=~Liangjian_Wen1">Liangjian Wen</a>, 
							<a href="https://scholar.google.com/citations?user=gXpdHzMAAAAJ&hl=en">Lili Pan</a>,
							<a href="http://faculty.hitsz.edu.cn/xuzenglin">Zenglin Xu</a>
              <br>
              <em>ICME</em>, 2021 
              <br>
              <a href="https://arxiv.org/pdf/2107.09242">[PDF]</a>
              <a href="https://github.com/Frankluox/FewShotCodeBase">[Code]</a>
              <p></p>
              <p>Applying contrastive learning to Few-Shot Learning, with views generated in a learning-to-learn fashion.</p>
            </td>
          </tr> 
	</tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Academic service</heading>
              <p>
		<br/>
		<strong>Conference reviewer</strong>
		<li>NeurIPS 2023</li> 
                <li>ICML 2022, 2024</li>
		<li>ICLR 2024</li> 
		<li>CVPR 2023, 2024</li>
		<li>ICCV 2023</li>
		<li>ECCV 2022, 2024</li>
		<li>CoLLAs 2023, 2024</li>
		<li>AAAI 2023</li>
		<br/>
		<strong>Journal reviewer</strong>
		<li>IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)</li>
		<li>IEEE Transactions on Image Processing (TIP)</li>
              </p>
            </td>
          </tr>
        </tbody></table>
          

          

        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;vertical-align:middle;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="vertical-align:middle;font-size:small;">
                This well-designed template is borrowed from this <a href="https://jonbarron.info/">guy</a>
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
