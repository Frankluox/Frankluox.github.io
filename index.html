<!DOCTYPE HTML>
<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?031f1c7d5b09cd718f3482df88fc8aa4";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Xu Luo</title>
  
  <meta name="author" content="Xu Luo">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/seal_icon.png">
  <style>
		ul{
			list-style-type: disc;
		}
	</style>
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Xu Luo</name>
              </p>
              <p>I am a Ph.D. candidate at UESTC, advised by Prof. <a href="https://cfm.uestc.edu.cn/~songjingkuan/">Jingkuan Song</a>.  My research aims to bridge the gap between virtual AI and the physical world by developing general-purpose robots, focusing on the creation of generalist policies that empower them to robustly perceive, dynamically interact, and continuously adaptâ€”ultimately enabling them to tackle any task, in any environment.
		      
		      
              
              <p style="text-align:center">
                <a href="mailto:Frank.Luox@outlook.com">Email</a> &nbsp/&nbsp
		<a href="./CV.pdf">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?hl=en&user=HXCdZMEAAAAJ">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/Frankluox">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/XuLuo-2.JPG"><img style="width:80%;max-width:80%" alt="profile photo" src="images/XuLuo-2.JPG" class="hoverZoomLink"></a>
            </td>
          </tr>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Selected Publications</heading>
            </td>
          </tr>
        </tbody></table>

	<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='images/shortcut.gif' width="180">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Shortcut Learning in Generalist Robot Policies: The Role of Dataset Diversity and Fragmentation</papertitle>
              <br>
			<a href="https://lucky-light-sun.github.io/">Youguang Xing*</a>,
		    <strong>Xu Luo*</strong>,
			<a href="https://scholar.google.com/citations?user=z6OXVpIAAAAJ&hl=en">Junlin Xie</a>,
		    <a href="https://lianligao.github.io/">Lianli Gao</a>,
		    <a href="https://scholar.google.com/citations?user=krryaDkAAAAJ&hl=en">Hengtao Shen</a>,
		    <a href="https://cfm.uestc.edu.cn/~songjingkuan/">Jingkuan Song</a>
              <br>
              <em>CoRL</em>, 2025
              <br>
	      <a href="https://arxiv.org/pdf/2508.06426">[PDF]</a>
		  <a href="https://lucky-light-sun.github.io/proj/shortcut-learning-in-grps/">[Website]</a>
              <p></p>
              <p>Identifying shortcut learning as a key impediment to the generalization of generalist robot policies and providing a comprehensive analysis.</p>
            </td>
          </tr>

	<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='images/lumina.png' width="180">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Lumina-T2X: Transforming Text into Any Modality, Resolution, and Duration via Flow-based Large Diffusion Transformers</papertitle>
              <br>
		    <a href="https://gaopengpjlab.github.io/">Peng Gao*</a>,
		    <a href="https://le-zhuo.com/">Le Zhuo*</a>,
		    <a href="https://scholar.google.com/citations?user=PxcXeWgAAAAJ&hl=en">Dongyang Liu*</a>,
		    <a href="https://ruoyidu.github.io/">Ruoyi Du*</a>,
		    <strong>Xu Luo*</strong>,
		    <a href="https://scholar.google.com/citations?user=j_8OPwwAAAAJ&hl=en">Longtian Qiu*</a>,
		    <a href="https://scholar.google.com.au/citations?hl=en&user=J4TYDDcAAAAJ">Yuhang Zhang</a>,
		    Chen Lin,
		    <a href="https://rongjiehuang.github.io/">Rongjie Huang</a>,
		    <a href="https://scholar.google.com/citations?user=wujqvGYAAAAJ&hl=en">Shijie Geng</a>,
		    <a href="https://zrrskywalker.github.io/">Renrui Zhang</a>,
		    Junlin Xi,
		    <a href="https://wqshao126.github.io/">Wenqi Shao</a>,
		    <a href="https://jiangzhengkai.github.io/">Zhengkai Jiang</a>,
		    <a href="https://violinarthur.github.io/">Tianshuo Yang</a>,
		    <a href="https://ywcmaike.github.io/">Weicai Ye</a>,
		    <a href="https://tonghe90.github.io/">Tong He</a>,
		    <a href="https://scholar.google.com/citations?hl=zh-CN&user=GUxrycUAAAAJ&view_op=list_works">Jingwen He</a>,
		    <a href="https://mmlab.siat.ac.cn/yuqiao">Yu Qiao</a>,
		    <a href="https://www.ee.cuhk.edu.hk/~hsli/">Hongsheng Li</a>
              <br>
			  <em>ICLR</em>, 2025 &nbsp <font color=#FF8080><strong>(Spotlight)</strong></font>
              <br>
	      <a href="https://arxiv.org/abs/2405.05945">[PDF]</a> 
	      <a href="https://github.com/Alpha-VLLM/Lumina-T2X">[Code]</a>
              <p></p>
              <p>Text-to-any-modality models that generate images, videos, audio, and 3D multiview images conditioned on text in a flow-based diffusion framework, using novel Flag-DiT architectures with up to 5B parameters and 128K context windows.</p>
            </td>
          </tr>

	<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='images/lessismore.png' width="180">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Less is More: On the Feature Redundancy of Pretrained Models When Transferring to Few-shot Tasks</papertitle>
              <br>
		    <strong>Xu Luo</strong>,
		    <a href="https://difanzou.github.io/">Difan Zou</a>,
		    <a href="https://lianligao.github.io/">Lianli Gao</a>,
		    <a href="http://faculty.hitsz.edu.cn/xuzenglin">Zenglin Xu</a>,
		    <a href="https://cfm.uestc.edu.cn/~songjingkuan/">Jingkuan Song</a>
              <br>
              <em>arXiv</em>, 2023
              <br>
	      <a href="https://arxiv.org/abs/2310.03843">[PDF]</a> 
              <p></p>
              <p>Uncovering and analyzing extreme feature redundancy phenomenon of pretrained vision models when transferring to few-shot tasks.</p>
            </td>
          </tr>

	<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='images/DETA.png' width="180">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>DETA: Denoised Task Adaptation for Few-shot Learning</papertitle>
              <br>
		    <a href="https://openreview.net/profile?id=~Ji_Zhang4">Ji Zhang</a>,
		    <a href="https://lianligao.github.io/">Lianli Gao</a>,
		    <strong>Xu Luo</strong>,
		    <a href="https://cfm.uestc.edu.cn/~shenht/">Hengtao Shen</a>,
		    <a href="https://cfm.uestc.edu.cn/~songjingkuan/">Jingkuan Song</a>
              <br>
              <em>ICCV</em>, 2023
              <br>
	      <a href="https://arxiv.org/abs/2303.06315">[PDF]</a> 
              <a href="https://github.com/nobody-1617/DETA">[Code]</a>
              <p></p>
              <p>Proposing DETA--a framework that solves potential data/label noise in downstream few-shot transfer tasks.</p>
            </td>
          </tr>
	      
	      
	<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='images/ICML_2023.jpeg' width="180">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>A Closer Look at Few-shot Classification Again</papertitle>
              <br>
		    <strong>Xu Luo*</strong>,
		    <a href="https://openreview.net/profile?id=~Hao_Wu37">Hao Wu*</a>,
		    <a href="https://openreview.net/profile?id=~Ji_Zhang4">Ji Zhang</a>,
		    <a href="https://lianligao.github.io/">Lianli Gao</a>,
		    <a href="https://scholar.google.com/citations?user=_UtHiH4AAAAJ&hl=zh-CN&oi=sra">Jing Xu</a>,
		    <a href="https://cfm.uestc.edu.cn/~songjingkuan/">Jingkuan Song</a>
              <br>
              <em>ICML</em>, 2023
              <br>
	      <a href="https://arxiv.org/abs/2301.12246">[PDF]</a> 
              <a href="https://github.com/Frankluox/CloserLookAgainFewShot">[Code]</a>
              <p></p>
              <p>Empirically proving the disentanglement of training and adaptation algorithms in few-shot classification, and performing interesting analysis of each phase that leads to the discovery of several important observations.</p>
            </td>
          </tr> 
	      
	<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='images/showing_img_nips2022.png' width="180">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Alleviating the Sample Selection Bias in Few-shot Learning by Removing Projection to the Centroid</papertitle>
              <br>
              <a href="https://scholar.google.com/citations?user=_UtHiH4AAAAJ&hl=zh-CN&oi=sra">Jing Xu</a>,
		    <strong>Xu Luo</strong>,
		    <a href="https://openreview.net/profile?id=~Xinglin_Pan1">Xinglin Pan</a>,
		    <a href="https://yananlix1.github.io/">Yanan Li</a>,
		    <a href="https://wenjiepei.github.io/">Wenjie Pei</a>,
							<a href="http://faculty.hitsz.edu.cn/xuzenglin">Zenglin Xu</a>
              <br>
              <em>NeurIPS</em>, 2022 &nbsp <font color=#FF8080><strong>(Spotlight)</strong></font>
              <br>
	      <a href="https://arxiv.org/abs/2210.16834">[PDF]</a> 
              <a href="https://github.com/KikimorMay/FSL-TCBR">[Code]</a>
              <p></p>
              <p>Revealing a strong bias caused by the centroid of features in each few-shot learning task. A simple method is designed to rectify this bias by removing the dimension along the direction of task centroid from the feature space.</p>
            </td>
          </tr> 
        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='images/showing_img5.png' width="180">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Channel Importance Matters in Few-Shot Image Classification</papertitle>
              <br>
              <strong>Xu Luo</strong>,
							<a href="https://scholar.google.com/citations?user=_UtHiH4AAAAJ&hl=zh-CN&oi=sra">Jing Xu</a>, 
							<a href="http://faculty.hitsz.edu.cn/xuzenglin">Zenglin Xu</a>
              <br>
              <em>ICML</em>, 2022
              <br>
              <a href="https://arxiv.org/abs/2206.08126">[PDF]</a>	
              <a href="https://github.com/Frankluox/Channel_Importance_FSL">[Code]</a>
              <p></p>
              <p>Revealing and analyzing the channel bias problem that we found critical in few-shot learning, through a simple channel-wise feature transformation applied only at test time.</p>
            </td>
          </tr> 
		
          <tr onmouseout="npil_stop()" onmouseover="npil_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='npil_image'>
                  <img src='images/showing_img3.png' width="180"></div>
                <img src='images/showing_img3.png' width="180">
              </div>
              <script type="text/javascript">
                function npil_start() {
                  document.getElementById('npil_image').style.opacity = "1";
                }

                function npil_stop() {
                  document.getElementById('npil_image').style.opacity = "0";
                }
                npil_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Rectifying the Shortcut Learning of Background for Few-Shot Learning</papertitle>
              <br>

              <strong>Xu Luo</strong>,
              <a href="https://joinwei-pku.github.io/longhuiwei.github.io/">Longhui Wei</a>, 
              <a href="https://openreview.net/profile?id=~Liangjian_Wen1">Liangjian Wen</a>,
              <a href="https://scholar.google.com/citations?user=8Of_NYQAAAAJ&hl=zh-CN">Jinrong Yang</a>,
              <a href="http://lingxixie.com/Home.html">Lingxi xie</a>,
              <a href="http://faculty.hitsz.edu.cn/xuzenglin">Zenglin Xu</a>,
              <a href="https://faculty.xidian.edu.cn/TQ1/zh_CN/index.htm">Qi Tian</a>
              <br>
							<em>NeurIPS</em>, 2021
              <br>
              <a href="https://arxiv.org/pdf/2107.07746.pdf">[PDF]</a> 
              <a href="https://github.com/Frankluox/FewShotCodeBase">[Code]</a>
              <p></p>
              <p>
              Identifying image background
              as a shortcut knowledge ungeneralizable
              beyond training categories in Few-Shot Learning. A novel framework, COSOC, is designed to
              tackle this problem.
              </p>
            </td>
          </tr>
					
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='images/showing_img4.png' width="180">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Boosting Few-Shot Classification with View-Learnable Contrastive Learning</papertitle>
              <br>
              <strong>Xu Luo</strong>,
							<a href="https://openreview.net/profile?id=~Yuxuan_Chen2">Yuxuan Chen</a>,
							<a href="https://openreview.net/profile?id=~Liangjian_Wen1">Liangjian Wen</a>, 
							<a href="https://scholar.google.com/citations?user=gXpdHzMAAAAJ&hl=en">Lili Pan</a>,
							<a href="http://faculty.hitsz.edu.cn/xuzenglin">Zenglin Xu</a>
              <br>
              <em>ICME</em>, 2021 
              <br>
              <a href="https://arxiv.org/pdf/2107.09242">[PDF]</a>
              <a href="https://github.com/Frankluox/FewShotCodeBase">[Code]</a>
              <p></p>
              <p>Applying contrastive learning to Few-Shot Learning, with views generated in a learning-to-learn fashion.</p>
            </td>
          </tr> 
          

          

        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;vertical-align:middle;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="vertical-align:middle;font-size:small;">
                This well-designed template is borrowed from this <a href="https://jonbarron.info/">guy</a>
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
